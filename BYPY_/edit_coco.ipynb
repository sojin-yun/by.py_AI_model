{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "############################ TRAIN DATASET ############################\n",
    "#######################################################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "file_data = OrderedDict()\n",
    "\n",
    "file_data[\"info\"] = {\"description\" : \"Train_Dataset_bypy\", \n",
    "                    \"url\" : \"https://aihub.or.kr/aidata/34121\",\n",
    "                    \"version\" : \"1.1\", \n",
    "                    \"year\" : 2020, \n",
    "                    \"contributor\" : \"미디어그룹사람과숲(컨)\", \n",
    "                    \"date_created\" : \"2021/08/25\", \n",
    "                    }\n",
    "file_data[\"licenses\"] = [{\"url\" : \"http://www.humanf.co.kr/\",\n",
    "                        \"id\" : 1,\n",
    "                        \"name\" : \"License\"}\n",
    "                        ]\n",
    "\n",
    "file_data[\"images\"] = []\n",
    "file_data[\"annotations\"] = []\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Training/coco_json/')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"rt\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "        contents = f.read() \n",
    "        json_data = json.loads(contents)\n",
    "        key_img = json_data[\"image\"]\n",
    "        date = key_img[\"date\"]\n",
    "        file_name = key_img[\"filename\"]\n",
    "        if \"MF\" in file_name:\n",
    "            fn = file_name.split('.')[0].split('N')[-1].split(\"MF\")\n",
    "        else:\n",
    "            tmp_fn1 = file_name.split('.')[0].split('N')[1].split('M')[0]\n",
    "            tmp_fn2 = file_name.split('.')[0].split(\"N\")[2]\n",
    "            fn.append(tmp_fn1)\n",
    "            fn.append(tmp_fn2)\n",
    "        img_id = \"3\" + fn[0] + fn[1]\n",
    "        width = key_img[\"resolution\"][0]\n",
    "        height = key_img[\"resolution\"][1]\n",
    "        \n",
    "        file_data[\"images\"].append(\n",
    "            {\n",
    "                \"license\": 1,\n",
    "                \"file_name\": file_name,\n",
    "                \"coco_url\": \"https://aihub.or.kr/aidata/34121/download\",\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"date_captured\": date,\n",
    "                \"id\": int(img_id)\n",
    "            })\n",
    "\n",
    "        key_annot = json_data[\"annotations\"]\n",
    "        for i in range(len(key_annot)):\n",
    "            annot_id = int(img_id + f\"{i}\")\n",
    "            class_id = int(key_annot[i][\"class\"])\n",
    "            if class_id != 1 and class_id != 2 and class_id != 3 and class_id != 4:\n",
    "                continue\n",
    "            if \"box\" in key_annot[i]: # bbox\n",
    "                key_box = key_annot[i][\"box\"]\n",
    "                xmin = key_box[0]\n",
    "                ymin = key_box[1]\n",
    "                xmax = key_box[2]\n",
    "                ymax = key_box[3]\n",
    "                bb_width = xmax-xmin\n",
    "                bb_height = ymax-ymin\n",
    "                file_data[\"annotations\"].append(\n",
    "                        {\n",
    "                            \"bbox\": [xmin, ymin, width, height],\n",
    "                            \"iscrowd\": 0,\n",
    "                            \"image_id\": int(img_id),\n",
    "                            \"category_id\": class_id,\n",
    "                            \"id\": annot_id\n",
    "                        })\n",
    "            else: # seg\n",
    "                key_poly = key_annot[i][\"polygon\"]\n",
    "                segmentation = [item for l in key_poly for item in l]\n",
    "                file_data[\"annotations\"].append(\n",
    "                        {\n",
    "                            \"segmentation\": segmentation,\n",
    "                            \"iscrowd\": 0,\n",
    "                            \"image_id\": int(img_id),\n",
    "                            \"category_id\": class_id,\n",
    "                            \"id\": annot_id\n",
    "                        })\n",
    "        f.close()\n",
    "\n",
    "file_data[\"categories\"] = [{\"supercategory\" : \"Smoke\", \"id\" : 1, \"name\" : \"Black smoke\"},\n",
    "                            {\"supercategory\" : \"Smoke\", \"id\" : 2, \"name\" : \"Gray smoke\"},\n",
    "                            {\"supercategory\" : \"Smoke\", \"id\" : 3, \"name\" : \"White smoke\"},\n",
    "                            {\"supercategory\" : \"Fire\", \"id\" : 4, \"name\" : \"Fire\"}]\n",
    "\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/labels/')\n",
    "#with open(\"train_info.json\", \"w\", encoding=\"utf-8\") as make_file:\n",
    "with open(\"train_info.json\", \"w\", encoding=\"UTF8\") as make_file:\n",
    "    json.dump(file_data, make_file, ensure_ascii=False)\n",
    "    make_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "############################ VALID DATASET ############################\n",
    "#######################################################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "file_data = OrderedDict()\n",
    "\n",
    "file_data[\"info\"] = {\"description\" : \"Validation_Dataset_bypy\", \n",
    "                    \"url\" : \"https://aihub.or.kr/aidata/34121\",\n",
    "                    \"version\" : \"1.1\", \n",
    "                    \"year\" : 2020, \n",
    "                    \"contributor\" : \"미디어그룹사람과숲(컨)\", \n",
    "                    \"date_created\" : \"2021/08/25\", \n",
    "                    }\n",
    "file_data[\"licenses\"] = [{\"url\" : \"http://www.humanf.co.kr/\",\n",
    "                        \"id\" : 1,\n",
    "                        \"name\" : \"License\"}\n",
    "                        ]\n",
    "\n",
    "file_data[\"images\"] = []\n",
    "file_data[\"annotations\"] = []\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Validation/coco_json/')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"rt\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "        contents = f.read() \n",
    "        json_data = json.loads(contents)\n",
    "        key_img = json_data[\"image\"]\n",
    "        date = key_img[\"date\"]\n",
    "        file_name = key_img[\"filename\"]\n",
    "        if \"MF\" in file_name:\n",
    "            fn = file_name.split('.')[0].split('N')[-1].split(\"MF\")\n",
    "        else:\n",
    "            tmp_fn1 = file_name.split('.')[0].split('N')[1].split('M')[0]\n",
    "            tmp_fn2 = file_name.split('.')[0].split(\"N\")[2]\n",
    "            fn.append(tmp_fn1)\n",
    "            fn.append(tmp_fn2)\n",
    "        img_id = \"3\" + fn[0] + fn[1]\n",
    "        width = key_img[\"resolution\"][0]\n",
    "        height = key_img[\"resolution\"][1]\n",
    "        \n",
    "        file_data[\"images\"].append(\n",
    "            {\n",
    "                \"license\": 1,\n",
    "                \"file_name\": file_name,\n",
    "                \"coco_url\": \"https://aihub.or.kr/aidata/34121/download\",\n",
    "                \"width\": width,\n",
    "                \"height\": height,\n",
    "                \"date_captured\": date,\n",
    "                \"id\": int(img_id)\n",
    "            })\n",
    "\n",
    "        key_annot = json_data[\"annotations\"]\n",
    "        for i in range(len(key_annot)):\n",
    "            annot_id = int(img_id + f\"{i}\")\n",
    "            class_id = int(key_annot[i][\"class\"])\n",
    "            if class_id != 1 and class_id != 2 and class_id != 3 and class_id != 4:\n",
    "                continue\n",
    "            if \"box\" in key_annot[i]: # bbox\n",
    "                key_box = key_annot[i][\"box\"]\n",
    "                xmin = key_box[0]\n",
    "                ymin = key_box[1]\n",
    "                xmax = key_box[2]\n",
    "                ymax = key_box[3]\n",
    "                bb_width = xmax-xmin\n",
    "                bb_height = ymax-ymin\n",
    "                file_data[\"annotations\"].append(\n",
    "                        {\n",
    "                            \"bbox\": [xmin, ymin, width, height],\n",
    "                            \"iscrowd\": 0,\n",
    "                            \"image_id\": int(img_id),\n",
    "                            \"category_id\": class_id,\n",
    "                            \"id\": annot_id\n",
    "                        })\n",
    "            else: # seg\n",
    "                key_poly = key_annot[i][\"polygon\"]\n",
    "                segmentation = [item for l in key_poly for item in l]\n",
    "                file_data[\"annotations\"].append(\n",
    "                        {\n",
    "                            \"segmentation\": segmentation,\n",
    "                            \"iscrowd\": 0,\n",
    "                            \"image_id\": int(img_id),\n",
    "                            \"category_id\": class_id,\n",
    "                            \"id\": annot_id\n",
    "                        })\n",
    "        f.close()\n",
    "\n",
    "file_data[\"categories\"] = [{\"supercategory\" : \"Smoke\", \"id\" : 1, \"name\" : \"Black smoke\"},\n",
    "                            {\"supercategory\" : \"Smoke\", \"id\" : 2, \"name\" : \"Gray smoke\"},\n",
    "                            {\"supercategory\" : \"Smoke\", \"id\" : 3, \"name\" : \"White smoke\"},\n",
    "                            {\"supercategory\" : \"Fire\", \"id\" : 4, \"name\" : \"Fire\"}]\n",
    "\n",
    "\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/labels/')\n",
    "with open(\"valid_info.json\", \"w\", encoding=\"UTF8\") as make_file:\n",
    "    json.dump(file_data, make_file, ensure_ascii=False)\n",
    "    make_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############################ FOR YOLOv5 ############################\n",
    "####################################################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Training/tmp_label')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"rt\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "        contents = f.read()\n",
    "        json_data = json.loads(contents)\n",
    "        key_img = json_data[\"image\"]\n",
    "        fn = key_img[\"filename\"]\n",
    "        file_name = fn.split('.')[0]\n",
    "        img_w = key_img[\"resolution\"][0]\n",
    "        img_h = key_img[\"resolution\"][1]\n",
    "        dw = 1/img_w\n",
    "        dh = 1/img_h\n",
    "\n",
    "        key_annot = json_data[\"annotations\"]\n",
    "        with open(f\"C:/Users/bypy/pypy/yolov5/data/labels/train/{file_name}.txt\", \"w\") as make_file:\n",
    "            for i in range(len(key_annot)):\n",
    "                class_id = int(key_annot[i][\"class\"]) - 1 # yolo는 0부터 시작\n",
    "                if \"box\" in key_annot[i]: # bbox\n",
    "                    key_box = key_annot[i][\"box\"]\n",
    "                    xmin = key_box[0]\n",
    "                    ymin = key_box[1]\n",
    "                    xmax = key_box[2]\n",
    "                    ymax = key_box[3]\n",
    "                    x = (xmin + xmax)/2.0\n",
    "                    y = (ymin + ymax)/2.0\n",
    "                    w = xmax - xmin\n",
    "                    h = ymax - ymin\n",
    "                    x = x*dw\n",
    "                    w = w*dw\n",
    "                    y = y*dh\n",
    "                    h = h*dh\n",
    "                    make_file.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n",
    "                else: # seg\n",
    "                    key_poly = key_annot[i][\"polygon\"]\n",
    "                    xlist=[]\n",
    "                    ylist=[]\n",
    "                    for j in key_poly:\n",
    "                        if len(j) == 2:\n",
    "                            xlist.append(j[0])\n",
    "                            ylist.append(j[1])\n",
    "                    xmin = min(xlist)\n",
    "                    xmax = max(xlist)\n",
    "                    ymin = min(ylist)\n",
    "                    ymax = max(ylist)\n",
    "                    x = (xmin + xmax)/2.0\n",
    "                    y = (ymin + ymax)/2.0\n",
    "                    w = xmax - xmin\n",
    "                    h = ymax - ymin\n",
    "                    x = x*dw\n",
    "                    w = w*dw\n",
    "                    y = y*dh\n",
    "                    h = h*dh\n",
    "                    make_file.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n",
    "            make_file.close()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "############################ FOR YOLOv5 ############################\n",
    "####################################################################\n",
    "\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Validation/label_SnF')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"rt\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "        contents = f.read()\n",
    "        json_data = json.loads(contents)\n",
    "        key_img = json_data[\"image\"]\n",
    "        fn = key_img[\"filename\"]\n",
    "        file_name = fn.split('.')[0]\n",
    "        img_w = key_img[\"resolution\"][0]\n",
    "        img_h = key_img[\"resolution\"][1]\n",
    "        dw = 1/img_w\n",
    "        dh = 1/img_h\n",
    "\n",
    "        key_annot = json_data[\"annotations\"]\n",
    "        with open(f\"C:/Users/bypy/Downloads/화재 발생 예측 영상/Validation/labels/{file_name}.txt\", \"w\") as make_file:\n",
    "            for i in range(len(key_annot)):\n",
    "                class_id = int(key_annot[i][\"class\"]) - 1 # yolo는 0부터 시작\n",
    "                if \"box\" in key_annot[i]: # bbox\n",
    "                    key_box = key_annot[i][\"box\"]\n",
    "                    xmin = key_box[0]\n",
    "                    ymin = key_box[1]\n",
    "                    xmax = key_box[2]\n",
    "                    ymax = key_box[3]\n",
    "                    x = (xmin + xmax)/2.0\n",
    "                    y = (ymin + ymax)/2.0\n",
    "                    w = xmax - xmin\n",
    "                    h = ymax - ymin\n",
    "                    x = x*dw\n",
    "                    w = w*dw\n",
    "                    y = y*dh\n",
    "                    h = h*dh\n",
    "                    make_file.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n",
    "                else: # seg\n",
    "                    key_poly = key_annot[i][\"polygon\"]\n",
    "                    xlist=[]\n",
    "                    ylist=[]\n",
    "                    for j in key_poly:\n",
    "                        if len(j) == 2:\n",
    "                            xlist.append(j[0])\n",
    "                            ylist.append(j[1])\n",
    "                    xmin = min(xlist)\n",
    "                    xmax = max(xlist)\n",
    "                    ymin = min(ylist)\n",
    "                    ymax = max(ylist)\n",
    "                    x = (xmin + xmax)/2.0\n",
    "                    y = (ymin + ymax)/2.0\n",
    "                    w = xmax - xmin\n",
    "                    h = ymax - ymin\n",
    "                    x = x*dw\n",
    "                    w = w*dw\n",
    "                    y = y*dh\n",
    "                    h = h*dh\n",
    "                    make_file.write(f\"{class_id} {x} {y} {w} {h}\\n\")\n",
    "            make_file.close()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/labels/valid')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for i in range(len(lines)):\n",
    "            a = lines[i].split(' ')[0]\n",
    "            #if a!='0' and a!='1' and a!='2' and a!='3':\n",
    "            if a!='0' and a!='1':\n",
    "                print(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# 이미지들의 주소 리스트로 만들어줌\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5')\n",
    "train_img_list = glob('./data/images/train/*.jpg')\n",
    "valid_img_list = glob('./data/images/valid/*.jpg')\n",
    "t_list = []\n",
    "v_list = []\n",
    "for timg in train_img_list:\n",
    "\ttimg = timg.split('images')[-1].replace(\"\\\\\",\"/\")\n",
    "\tt_list.append(timg)\n",
    "\n",
    "\n",
    "for vimg in valid_img_list:\n",
    "\tvimg = vimg.split('images')[-1]\n",
    "\tv_list.append(vimg)\n",
    "\n",
    "\n",
    "# 리스트를 txt파일로 생성\n",
    "with open('./data/images/train.txt', 'w') as f:\n",
    "\tf.write('\\n.'.join(t_list) + '\\n')\n",
    "    \n",
    "with open('./data/images/valid.txt', 'w') as f:\n",
    "\tf.write('\\n.'.join(v_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MEDICAL IT\\pypy\\yolov5\\data\\images\\train\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/images/train/')\n",
    "train_img_list = os.listdir('.')\n",
    "tttt = []\n",
    "for timg in train_img_list:\n",
    "    t_img = timg.split('MF')[0]\n",
    "    if t_img not in tttt:\n",
    "        tttt.append(t_img)\n",
    "\n",
    "print(len(tttt))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 4 to 2 (train)\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/tmp_fold/origin_valid')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        with open('C:/Users/bypy/pypy/yolov5/data/tmp_fold/valid_3/' + fp, \"w\") as ftmp:\n",
    "            for i in range(len(lines)):\n",
    "                a = lines[i][0]\n",
    "                if a=='0' or a=='1':\n",
    "                    lines[i] = '0 ' + lines[i][2:]\n",
    "                elif a=='2':\n",
    "                    lines[i] = '1 ' + lines[i][2:]\n",
    "                else:\n",
    "                    lines[i] = '2 ' + lines[i][2:]\n",
    "                ftmp.write(lines[i])\n",
    "            ftmp.close()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class 4 to 2 (valid)\n",
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.chdir('C:/Users/bypy/pypy/yolov5/data/labels/valid')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        with open('C:/Users/bypy/pypy/yolov5/data/labels/valid_2/'+fp, \"w\") as ftmp:\n",
    "            for i in range(len(lines)):\n",
    "                a = lines[i][0]\n",
    "                if a=='0' or a=='1' or a=='2':\n",
    "                    lines[i] = '0 '+lines[i][2:]\n",
    "                else:\n",
    "                    lines[i] = '1 '+lines[i][2:]\n",
    "                ftmp.write(lines[i])\n",
    "            ftmp.close()\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "연습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = {\"annotations\": [{\"bbox\":\"ddd\", 'id':'dfsd'}, {\"seg\":\"ddd\", 'id':'dfsd'}]}\n",
    "if \"bbox\" in fd[\"annotations\"][0]:\n",
    "    print(\"true\")\n",
    "import os \n",
    "import json\n",
    "with open(\"annot.json\", \"r\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "    contents = f.read() \n",
    "    json_data = json.loads(contents)\n",
    "    jj = json_data[\"info\"]\n",
    "    if \"url\" not in jj:\n",
    "        print(\"no\")\n",
    "    else:\n",
    "        print(\"true\")\n",
    "\n",
    "gg = \"04\"\n",
    "print(int(gg),\"\\n\")\n",
    "bb = [55,44,55,22]\n",
    "\n",
    "bbb = [item for l in bb for item in l]\n",
    "print(bbb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Validation/label_SnF')\n",
    "for fp in os.listdir('.'):\n",
    "    filename = fp.split('.')[0]\n",
    "    print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import OrderedDict\n",
    "\n",
    "os.chdir('C:/Users/bypy/Downloads/화재 발생 예측 영상/Validation/label_SnF')\n",
    "for fp in os.listdir('.'):\n",
    "    with open(fp, \"r\", newline='', encoding=\"utf-8-sig\") as f:\n",
    "        contents = f.read() \n",
    "        json_data = json.loads(contents)\n",
    "        for i in range(len(json_data['annotations'])-1,-1,-1):\n",
    "            data = json_data['annotations'][i]['class']\n",
    "            if data!='01' and data!='02' and data!='03' and data!='04':\n",
    "                del json_data['annotations'][i]\n",
    "                print(f\"class {data} is deleted!\")\n",
    "        f.close()\n",
    "        \n",
    "        with open(fp, 'w') as file:\n",
    "            json.dump(json_data, file, indent=4)\n",
    "            file.close()\n",
    "            print(fp , \"is completed!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "239788a4709e20e1b60e6fa829e882864c3094b29ad7bd5ce7c0c6d76c876173"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
